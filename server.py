
# streamlit run server.py
import streamlit as st 
# from skimage import io
# from skimage.transform import resize
import numpy as np  
import torch
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
import torch
import torch. nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import warnings
from sklearn.model_selection import train_test_split
from streamlit_echarts import st_echarts
import torch 
import torch.nn as nn 
import torch.optim as optim 
import numpy as np 
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm 
import matplotlib.pyplot as plt 
import random 
from torch.nn.utils.rnn import pad_sequence
from sklearn.model_selection import train_test_split
from collections import Counter
from torchtext.vocab import vocab

from torchtext.data.utils import get_tokenizer
import os
import pandas as pd
import torch
from collections import Counter

# æ¨¡å‹è¼‰å…¥
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
@st.cache_resource 

def load_model_1():#lstm_1
    
    class LSTM_1(nn.Module):
        
        def __init__(self, input_dim, hidden_dim, num_layers, output_dim):
            super(LSTM_1, self).__init__()
            self.hidden_dim = hidden_dim
            self.num_layers = num_layers
            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)  
            self.fc = nn.Linear(hidden_dim, output_dim)
            self.dropout = nn.Dropout(0.1) 

        def forward(self, x):
        
            batch_size = x.size(0)
            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)
            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)
            out, _ = self.lstm(x, (h0, c0)) 
            out = self.dropout(out)
            out = self.fc(out[:, -1, :])
            return out
        
    input_dim = 7
    hidden_dim =64
    num_layers = 2
    output_dim = 1
    weightpath='LSTM.pth'
    state_dict = torch.load(weightpath, map_location=device)
    model_1 = LSTM_1(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)
    model_1.load_state_dict(state_dict) 
    model_1 = model_1.to(device)
    model_1.eval()
    return model_1

model_1 = load_model_1()
one_time=0
# if(one_time==0):
#     df = pd.read_csv('lstm_ana\sentimentData\IMDB Dataset.csv')
#     reviews = df['review'].values
#     sentiments = df['sentiment'].values
#     tokenizer = get_tokenizer('basic_english')
#     counter = Counter()
#     for review in reviews:
#         token = tokenizer(review)
#         counter.update(token)
#     one_time=1
#     token_vocab = vocab(counter, min_freq=15, specials=('<pad>', '<unk>'))
#     token_vocab.set_default_index(token_vocab.get_stoi()['<unk>'])

#     PAD_IDX = token_vocab.get_stoi()['<pad>']
#     INPUT_DIM = len(token_vocab)

#     reviews_ids = [torch.tensor(token_vocab.lookup_indices(tokenizer(i))) for i in reviews]
#     labels = (sentiments=='positive').astype('float32')
@st.cache_resource
def load_and_process_data(file_path, min_freq=15):
    """
    åŠ è¼‰æ•¸æ“šä¸¦é€²è¡Œåˆ†è©å’Œè©å½™è¡¨å»ºç«‹ã€‚
    æ­¤å‡½æ•¸åƒ…é‹è¡Œä¸€æ¬¡ï¼Œè¿”å›åˆ†è©å™¨å’Œè©å½™è¡¨ã€‚
    """
    # åŠ è¼‰ CSV æ–‡ä»¶
    df = pd.read_csv(file_path)
    reviews = df['review'].values
    sentiments = df['sentiment'].values

    # åˆå§‹åŒ–åˆ†è©å™¨
    tokenizer = get_tokenizer('basic_english')

    # è¨ˆæ•¸å–®è©é »ç‡
    counter = Counter()
    for review in reviews:
        token = tokenizer(review)
        counter.update(token)

    # å»ºç«‹è©å½™è¡¨
    token_vocab = vocab(counter, min_freq=min_freq, specials=('<pad>', '<unk>'))
    token_vocab.set_default_index(token_vocab.get_stoi()['<unk>'])

    return tokenizer, token_vocab, reviews, sentiments


# åŠ è¼‰æ•¸æ“šå’Œè©å½™è¡¨
file_path = 'IMDB_Dataset.csv'
tokenizer, token_vocab, reviews, sentiments = load_and_process_data(file_path)
PAD_IDX = token_vocab.get_stoi()['<pad>']
INPUT_DIM = len(token_vocab)



def load_model_2():#lstm_2
    
    class IMDB(Dataset):
        def __init__(self, x, y):
            self.x = x
            self.y = y
            
        def __getitem__(self, index):
            return self.x[index], self.y[index]
        
        def __len__(self):
            return len(self.x)

    class LSTM_2(nn.Module):
        def __init__(self, embedding_dim, hidden_size, num_layers=1, bidirectional=True):
            super().__init__()
            self.embedding = nn.Embedding(INPUT_DIM,  embedding_dim, padding_idx = PAD_IDX)
            self.lstm =nn.LSTM(embedding_dim, 
                            hidden_size = hidden_size, 
                            num_layers = num_layers,
                            bidirectional = bidirectional,
                            batch_first=True
            )

            hidden = hidden_size * 2 if bidirectional else hidden_size
            self.fc = nn.Linear(hidden, 1)

            self.sigmoid = nn.Sigmoid()

        def forward(self, x):
            emb_out = self.embedding(x)
            out, (h, c)  = self.lstm(emb_out)
            x = out[:, -1, :]
            x = self.fc(x)
            print(x.shape)
            return self.sigmoid(x)
        
        
    model_2 = LSTM_2(embedding_dim = 300, hidden_size= 512).to(device)

    model_path='mode5l.pt'

    model_2.load_state_dict(torch.load(model_path, map_location=device))
    model_2.eval()
    return model_2

model_2 = load_model_2()

def display_bar_chart():
    # é…ç½®ç›´æ–¹åœ–é¸é …
    option = {
        "backgroundColor": "#212121",
        "title": {
            "text": "å„æ¨¡å‹æ¨¡æ“¬äº¤æ˜“å¹³å‡å¹´åŒ–ç‡(%)",
            "subtext": "è³‡æ–™ç¯„åœ:2019/04/19-2024/04/10",
            "x": "left",
            "textStyle": {
                "color": "#f2f2f2"
            }
        },
        "tooltip": {
            "trigger": "axis",
            "axisPointer": {
                "type": "shadow"
            }
        },
        "legend": {
            "data": ["å¹´åŒ–ç‡"],
            "textStyle": {
                "color": "#f2f2f2"
            }
        },
        "xAxis": {
            "type": "category",
            "data": ["lstm", "cnn", "lstm-GAN", "gru", "gru-GAN","å‡å€¼å›æ­¸(MRS)"],
            "axisLine": {
                "lineStyle": {
                    "color": "#f2f2f2"
                }
            },
            "axisLabel": {
 
                "interval": 0 
            }
        },
        "yAxis": {
            "type": "value",
            "axisLine": {
                "lineStyle": {
                    "color": "#f2f2f2"
                }
            }
        },
        "series": [
            {
                "name": "å¹´åŒ–ç‡",
                "type": "bar",
                "data": [9,15,24,8,16,6],
                "itemStyle": {
                    "color": "#ef4136"
                }
            }
        ]
    }

    # ä½¿ç”¨ streamlit-echarts é¡¯ç¤ºç›´æ–¹åœ–
    st_echarts(options=option, height="600px")

st.title("å°ç£åŠ æ¬ŠæŒ‡æ•¸(^TWII)")
st.caption("å‚™è¨»ï¼šæ•¸æ“šä¾†æºç‚º Yahoo Financeï¼Œæ›´æ–°é–“éš”ç‚º 1 åˆ†é˜ã€‚ä¸”ä¸åŒ…å«ç›¤å¾Œæ•¸æ“šã€‚")

import yfinance as yf
import streamlit as st
stock_code = "^TWII"
stock = yf.Ticker(stock_code)
data_today = stock.history(period="1d", interval="1m")  
data_recent = stock.history(period="5d", interval="1d") #
if not data_today.empty and len(data_recent) >= 2:
    # ä»Šæ—¥é–‹ç›¤åƒ¹ã€æœ€é«˜åƒ¹ã€æœ€ä½åƒ¹
    today_open = data_today["Close"].iloc[-1]
    today_high = data_today["High"].max()
    today_low = data_today["Low"].min()  
    
    # å‰ä¸€å¤©æ”¶ç›¤åƒ¹
    yesterday_close = data_recent["Close"].iloc[-2]
    yesterday_h = data_today["High"].iloc[-2]
    yesterday_l = data_today["Low"].iloc[-2]
    # è¨ˆç®—å·®ç•°
    open_diff = today_open - yesterday_close
    high_diff = today_high - yesterday_h
    low_diff = today_low - yesterday_l
    open_diff = today_open - yesterday_close
    high_diff = today_high - yesterday_h
    low_diff = today_low - yesterday_l
    
    open_pct = (open_diff / yesterday_close) * 100
    high_pct = (high_diff / yesterday_h) * 100
    low_pct = (low_diff / yesterday_l) * 100
    col31, col32, col33 = st.columns(3)
    col31.metric("æ™‚å¯¦æ•¸æ“š", f"{today_open:.2f}", f"{open_diff:+.2f} ({open_pct:+.2f}%)")
    col32.metric("ä»Šæ—¥æœ€é«˜", f"{today_high:.2f}", f"{high_diff:+.2f} ({high_pct:+.2f}%)")
    col33.metric("ä»Šæ—¥æœ€ä½", f"{today_low:.2f}", f"{low_diff:+.2f} ({low_pct:+.2f}%)")
else:
    st.error("ç„¡æ³•ç²å–å®Œæ•´çš„æ•¸æ“šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")

# æ¨™é¡Œ
st.title("æ¸¬è©¦ä¸­")

import streamlit as st

# å‰µå»ºä¸‰å€‹åˆ—
col1, col2, col3 = st.columns(3)

# åœ¨æ¯å€‹åˆ—ä¸­æ”¾ç½®ä¸€å€‹æŒ‰éˆ•
with col1:
    clicked1 = st.button("æŒ‰éˆ•1", help="é¸æ“‡æ¨¡å‹1")

with col2:
    clicked2 = st.button("æŒ‰éˆ•2", help="é¸æ“‡æ¨¡å‹2")

with col3:
    clicked3 = st.button("æŒ‰éˆ•3", help="é¸æ“‡æ¨¡å‹3")

# æ ¹æ“šæŒ‰éˆ•çš„é»æ“Šç‹€æ…‹åŸ·è¡Œç›¸æ‡‰æ“ä½œ
if clicked1:
    st.write("æŒ‰éˆ•1è¢«é»æ“Šäº†ï¼")
    #display_bar_chart()

if clicked2:
    st.write("æŒ‰éˆ•2è¢«é»æ“Šäº†ï¼")

if clicked3:
    st.write("æŒ‰éˆ•3è¢«é»æ“Šäº†ï¼")


#åˆ†è©


    





uploaded_file = st.file_uploader("æ¸¬è©¦")
from google.cloud import translate_v2 as translate
if uploaded_file is not None:
    ee=[]
    try:
        def transform_data(df):

            data_index =  ['Close','Volume2','h-l','sma','10ema','greed','adr']
        
            flatten_data = df[data_index].values.reshape(-1)  # æ”¤å¹³è³‡æ–™
            
            # è½‰æ›æˆå­—ä¸²
            str_data = "<SEP>".join(flatten_data.astype('str'))
            filter_data = str_data.replace(',',"").replace('X',"")
            
            # åˆ‡å‰²å›é™£åˆ—
            x_data = filter_data.split("<SEP>")
            
            return x_data
            
        x = []
        df = pd.read_csv(uploaded_file)
        df2=df['Close']
        data = transform_data(df)

        data_index=['Close']
        data2 = df[data_index].values.reshape(-1)  # æ”¤å¹³è³‡æ–™
        ee.extend(data2)

        x.extend(data)
        sc = MinMaxScaler()
        sc_2 = MinMaxScaler()


        x = np.array(x).astype('float')
        x = x.reshape(-1, len(['Close','Volume2','h-l','sma','10ema','greed','adr']))

        ee = np.array(ee).astype('float')
        ee = ee.reshape(-1, 1)
        ee=sc_2.fit_transform(ee)

        x = sc.fit_transform(x)
        y = x[:,0]


        def split_data(datas, labels, split_num = 10):
            max_len = len(datas)
            x, y = [], []
            for i in range(max_len - split_num -1):
                x.append(datas[i: i+split_num])
                y.append(labels[split_num+i+1])
            
            return np.array(x), np.array(y)


        x_train, x_valid, y_train, y_valid = train_test_split(x, y, train_size=1, shuffle=False)

        x_valid, y_valid = split_data(x_valid, y_valid)

        x_valid=torch.from_numpy(x_valid).type(torch.Tensor)
        y_valid=torch.from_numpy(y_valid).float().unsqueeze(1)
        x_valid = x_valid
        y_valid=y_valid

        with torch.no_grad():
            x_valid = x_valid.to(device)  # Move x_valid to the same device as the model
            y_pred = model_1(x_valid)
        y_pred = y_pred.cpu().numpy()
        y_valid = y_valid.cpu().numpy()
        y_pred_inverse = sc_2.inverse_transform(y_pred)
        y_valid_inverse = sc_2.inverse_transform(y_valid)
        # print(y_pred_inverse.item())#é æ¸¬
        # print(y_valid_inverse.item())#åŸå§‹
        

        def display_predictions(y_pred_inverse, y_valid_inverse):
            template = f"""
            ### é æ¸¬çµæœé æ¸¬:{round(y_pred_inverse.item(),1)}
            

            ### é æ¸¬çµæœåŸå§‹:{y_valid_inverse.item()}
            
            """
            st.markdown(template)

        display_predictions(y_pred_inverse, y_valid_inverse)
    except Exception as e:
         st.error(f"æ–‡ä»¶è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤è«‹ç¢ºèªä¸Šå‚³æ–‡ä»¶æ ¼å¼")
    
# Store the initial value of widgets in session state
if "visibility" not in st.session_state:
    st.session_state.visibility = "visible"
    st.session_state.disabled = False


text_input = st.text_input(
    "Enter some text ğŸ‘‡",
    placeholder="è¼¸å…¥æ–‡ç« ",
    label_visibility="visible",
    disabled=False,

)

import googletrans
if text_input:
    from translate import Translator
    label_decoding = {0:'negative', 1:'positive'}
   
    def predict_sentiment(text):
        # è‡ªå‹•è½‰ç¾©å–®å¼•è™Ÿ
    

        # æ­¥é©Ÿ 1ï¼šåˆ†è©å’Œç·¨ç¢¼
        tokens = tokenizer(text)  # ä½¿ç”¨åˆ†è©å™¨å°‡æ–‡æœ¬åˆ†è©
        indices = token_vocab.lookup_indices(tokens)  # å°‡åˆ†è©çµæœè½‰æ›ç‚ºæ•¸å­—ç´¢å¼•
        text_tensor = torch.tensor(indices).unsqueeze(0).to(device)  # å°‡æ•¸å­—ç´¢å¼•è½‰æ›ç‚ºTensorä¸¦åŠ å…¥batchç¶­åº¦

        # æ­¥é©Ÿ 2ï¼šä½¿ç”¨æ¨¡å‹é€²è¡Œé æ¸¬
        model_2.eval()  # è¨­ç½®æ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è¨ˆç®—
            output = model_2(text_tensor)  # æ¨¡å‹é æ¸¬
            prediction = torch.sigmoid(output).item()  # å–å‡ºé æ¸¬çµæœä¸¦æ‡‰ç”¨sigmoidå‡½æ•¸
        pred = (output.view(-1) > 0.5)
        return label_decoding[int(pred)]
        #print('Pred Label:',label_decoding[int(pred)])             # é¡¯ç¤ºæ–‡å­— 

    # ç¤ºä¾‹è¼¸å…¥
    user_input=text_input
    translation = translator.translate(user_input, src='zh-tw',dest='en') 
    user_input = translation.text

    
    tokenizer = get_tokenizer('basic_english')
    ans=predict_sentiment(user_input)
    if(ans=='positive'):{
        st.balloons()
    }
    else:
        st.snow()
    
    st.write("è¼¸å…¥æ–‡ç« æƒ…ç·’ï¼š", ans)

